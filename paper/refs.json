[
  {"id":"HeadExtentConsequencesPHacking2015","abstract":"Publication bias resulting from so-called \"p-hacking\" is pervasive throughout the life sciences; however, its effects on general conclusions made from the literature appear to be weak.","accessed":{"date-parts":[[2015,3,14]]},"author":[{"family":"Head","given":"Megan L."},{"family":"Holman","given":"Luke"},{"family":"Lanfear","given":"Rob"},{"family":"Kahn","given":"Andrew T."},{"family":"Jennions","given":"Michael D."}],"container-title":"PLoS Biol","container-title-short":"PLoS Biol","DOI":"10.1371/journal.pbio.1002106","issue":"3","issued":{"date-parts":[[2015,3,13]]},"page":"e1002106","source":"PLoS Journals","title":"The Extent and Consequences of P-Hacking in Science","type":"article-journal","URL":"http://dx.doi.org/10.1371/journal.pbio.1002106","volume":"13"},
  {"id":"MeehlTheoryTestingPsychologyPhysics1967","abstract":"Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1/2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by \"success\" is very weak, and becomes weaker with increased precision. \"Statistical significance\" plays a logical role in psychology precisely the reverse of its role in physics. This problem is worsened by certain unhealthy tendencies prevalent among psychologists, such as a premium placed on experimental \"cuteness\" and a free reliance upon ad hoc explanations to avoid refutation.","accessed":{"date-parts":[[2016,8,16]]},"author":[{"family":"Meehl","given":"Paul E."}],"container-title":"Philosophy of Science","container-title-short":"Philosophy of Science","ISSN":"0031-8248","issue":"2","issued":{"date-parts":[[1967]]},"page":"103-115","source":"JSTOR","title":"Theory-Testing in Psychology and Physics: A Methodological Paradox","title-short":"Theory-Testing in Psychology and Physics","type":"article-journal","URL":"http://www.jstor.org.proxy1.lib.uwo.ca/stable/186099","volume":"34"},
  {"id":"SimonsohnPcurveKeyFiledrawer2014","accessed":{"date-parts":[[2020,1,21]]},"author":[{"family":"Simonsohn","given":"Uri"},{"family":"Nelson","given":"Leif D."},{"family":"Simmons","given":"Joseph P."}],"container-title":"Journal of Experimental Psychology: General","container-title-short":"Journal of Experimental Psychology: General","DOI":"10.1037/a0033242","ISSN":"1939-2222, 0096-3445","issue":"2","issued":{"date-parts":[[2014]]},"language":"en","page":"534-547","source":"DOI.org (Crossref)","title":"P-curve: A key to the file-drawer.","title-short":"P-curve","type":"article-journal","URL":"http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033242","volume":"143"},
  {"id":"YoungReliabilityEnvironmentalEpidemiology2019","abstract":"Claims made in science papers are coming under increased scrutiny with many claims failing to replicate. Meta-analyses are questionable when based on data from observational studies which are often unreliable. We examine the reliability of the base studies used in an air quality/heart attack meta-analysis and the resulting meta-analysis. A meta-analysis study that includes 14 observational air quality/heart attack studies is examined for its statistical reliability. We use simple counting to evaluate the reliability of the base papers and a p-value plot of the p-values from the base studies to examine study heterogeneity. We find that the base papers have the potential for massive multiple testing and multiple modeling with no statistical adjustments. Statistics coming from the base papers are not guaranteed to be unbiased, a requirement for a valid meta-analysis. There is study heterogeneity for the base papers with strong evidence for so called p-hacking in some, possibly many, of the studies. We make two observations: there are many claims at issue in each of the 14 base studies so uncorrected multiple testing is a serious issue. We find that some of the base papers exhibit the characteristics of p-hacking and are therefore not reliable; the resulting meta-analysis is not reliable.","accessed":{"date-parts":[[2019,1,1]]},"author":[{"family":"Young","given":"S. Stanley"},{"family":"Acharjee","given":"Mithun Kumar"},{"family":"Das","given":"Kumer"}],"container-title":"Regulatory Toxicology and Pharmacology","container-title-short":"Regulatory Toxicology and Pharmacology","DOI":"10.1016/j.yrtph.2018.12.013","ISSN":"0273-2300","issued":{"date-parts":[[2019,3,1]]},"page":"47-52","source":"ScienceDirect","title":"The reliability of an environmental epidemiology meta-analysis, a case study","type":"article-journal","URL":"http://www.sciencedirect.com/science/article/pii/S0273230018303209","volume":"102"}
]
